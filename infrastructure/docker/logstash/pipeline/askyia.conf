input {
  # Receive logs from Filebeat
  beats {
    port => 5044
  }
  
  # Direct TCP input for application logs (JSON)
  tcp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # Parse JSON logs from application
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed"
      skip_on_invalid_json => true
    }
    
    if [parsed] {
      mutate {
        rename => {
          "[parsed][level]" => "level"
          "[parsed][timestamp]" => "log_timestamp"
          "[parsed][service]" => "service"
          "[parsed][correlation_id]" => "correlation_id"
          "[parsed][workflow_id]" => "workflow_id"
          "[parsed][execution_id]" => "execution_id"
          "[parsed][node_id]" => "node_id"
          "[parsed][user_id]" => "user_id"
          "[parsed][message]" => "log_message"
          "[parsed][logger]" => "logger_name"
          "[parsed][source]" => "source_info"
        }
        remove_field => ["parsed"]
      }
    }
  }

  # Add application metadata
  mutate {
    add_field => {
      "application" => "askyia"
      "environment" => "development"
    }
  }

  # Parse timestamp
  if [log_timestamp] {
    date {
      match => ["log_timestamp", "ISO8601"]
      target => "@timestamp"
    }
  }

  # Categorize log levels
  if [level] {
    mutate {
      uppercase => ["level"]
    }
    
    if [level] == "ERROR" or [level] == "CRITICAL" {
      mutate {
        add_tag => ["error"]
      }
    }
    
    if [level] == "WARNING" {
      mutate {
        add_tag => ["warning"]
      }
    }
  }

  # Workflow execution specific processing
  if [workflow_id] and [execution_id] {
    mutate {
      add_tag => ["workflow_execution"]
    }
  }

  # Node execution processing
  if [node_id] and [node_type] {
    mutate {
      add_tag => ["node_execution"]
    }
  }

  # Extract duration metrics
  if [duration_ms] {
    ruby {
      code => "
        duration = event.get('duration_ms').to_f
        event.set('duration_bucket', 
          case duration
          when 0..100 then 'fast'
          when 100..500 then 'normal'
          when 500..2000 then 'slow'
          else 'very_slow'
          end
        )
        event.set('duration_seconds', duration / 1000.0)
      "
    }
  }

  # HTTP request processing
  if [method] and [path] and [status_code] {
    mutate {
      add_tag => ["http_request"]
    }
  }
}

output {
  # Main index for all logs
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "askyia-logs-%{+YYYY.MM.dd}"
  }
  
  # Separate index for workflow executions
  if "workflow_execution" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "askyia-workflows-%{+YYYY.MM.dd}"
    }
  }
  
  # Separate index for errors
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "askyia-errors-%{+YYYY.MM.dd}"
    }
  }

  # Separate index for HTTP requests
  if "http_request" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "askyia-http-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output (uncomment for troubleshooting)
  # stdout { codec => rubydebug }
}